{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.beta.ons.gov.uk/v1/datasets/ashe-tables-7-and-8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "def write_time_column(data):\n",
    "    data[\"title\"].append(\"Year\")\n",
    "    data[\"name\"].append(\"year\")\n",
    "    data[\"component_attachment\"].append(\"qb:dimension\")\n",
    "    data[\"property_template\"].append(\"http://purl.org/linked-data/sdmx/2009/dimension#refPeriod\")\n",
    "    data[\"value_template\"].append(\"http://reference.data.gov.uk/id/year/{year}\")\n",
    "    data[\"datatype\"].append(\"string\")\n",
    "    data[\"value_transformation\"].append(\"\")\n",
    "    data[\"regex\"].append(\"\")\n",
    "    data[\"range\"].append(\"\")\n",
    "    return data\n",
    "def write_admin_geography(data):\n",
    "    data[\"title\"].append(\"Geography\")\n",
    "    data[\"name\"].append(\"geography\")\n",
    "    data[\"component_attachment\"].append(\"qb:dimension\")\n",
    "    data[\"property_template\"].append(\"http://purl.org/linked-data/sdmx/2009/dimension#refArea\")\n",
    "    data[\"value_template\"].append(\"http://statistics.data.gov.uk/id/statistical-geography/{geography}\")\n",
    "    data[\"datatype\"].append(\"string\")\n",
    "    data[\"value_transformation\"].append(\"\")\n",
    "    data[\"regex\"].append(\"[A-Z][0-9]{8}\")\n",
    "    data[\"range\"].append(\"\")\n",
    "    return data\n",
    "# TODO - these should be automatically included in the new columns.csv's\n",
    "# code lists that we dont want to convert for...reasons\n",
    "NON_STANDARD = {\n",
    "    \"calendar-years\": {\n",
    "        \"write_column\": write_time_column\n",
    "    },\n",
    "    \"admin-geography\": {\n",
    "        \"write_column\": write_admin_geography\n",
    "    }\n",
    "}\n",
    "def get_unique_codelist_urls_from_a_dataset(url):\n",
    "    codelist_list = []\n",
    "    # Get the dataset info\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        raise ValueError(\"Failed with status code: \" + r.status_code)\n",
    "    dataset_as_dict = r.json()\n",
    "    lastest_version_url = dataset_as_dict[\"links\"][\"latest_version\"][\"href\"]\n",
    "    #  Get the lastest version of that dataset info\n",
    "    r = requests.get(lastest_version_url)\n",
    "    if r.status_code != 200:\n",
    "        raise ValueError(\"Failed with status code: \" + r.status_code)\n",
    "    lastest_version_as_dict = r.json()\n",
    "    # For each dimension\n",
    "    for dimension in lastest_version_as_dict[\"dimensions\"]:\n",
    "        code_list_url = \"https://api.beta.ons.gov.uk/v1/code-lists/{}/editions/one-off/codes\".format(dimension[\"id\"])\n",
    "        codelist_list.append(code_list_url)\n",
    "    return codelist_list\n",
    "def create_codelist_reference_csv_from_codelist_url(url):\n",
    "    #  Get the lastest version of that dataset info\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        raise ValueError(\"Failed with status code: \" + r.status_code)\n",
    "    code_list_info = r.json()\n",
    "    # Get the codelist id\n",
    "    code_list_id = code_list_info[\"items\"][0][\"links\"][\"code_list\"][\"href\"].split(\"/\")[-1]\n",
    "    if code_list_id in NON_STANDARD.keys():\n",
    "        return \n",
    "    df_dict = {\n",
    "        \"Label\":[],\n",
    "        \"Notation\":[],\n",
    "        \"Parent Notation\":[],\n",
    "        \"Sort Priority\":[]\n",
    "    }\n",
    "    for code_list in code_list_info[\"items\"]:\n",
    "        df_dict[\"Label\"].append(code_list[\"label\"])\n",
    "        df_dict[\"Notation\"].append(code_list[\"code\"])\n",
    "        df_dict[\"Parent Notation\"].append(\"\")\n",
    "        df_dict[\"Sort Priority\"].append(\"\")\n",
    "    df = pd.DataFrame().from_dict(df_dict)\n",
    "    df.to_csv(\"reference/codelists/{}.csv\".format(code_list_id), index=False)\n",
    "def get_list_of_code_list_url_for_list_of_datasets(dataset_url_list):\n",
    "    all_code_lists = []\n",
    "    for dataset in dataset_url_list:\n",
    "        code_list_urls_from_dataset = get_unique_codelist_urls_from_a_dataset(dataset)\n",
    "    for code_list_url in code_list_urls_from_dataset:\n",
    "        if code_list_url not in all_code_lists:\n",
    "            all_code_lists.append(code_list_url)\n",
    "    return all_code_lists\n",
    "def populate_codelist_reference_csvs_from_codelist_urls(code_list_urls_from_dataset):\n",
    "    for cl in code_list_urls_from_dataset:\n",
    "        create_codelist_reference_csv_from_codelist_url(cl)\n",
    "def components_csv_from_list_of_code_list_urls(code_list_urls_from_dataset, details):\n",
    "    columns=[\"Label\", \"Description\", \"Component Type\", \"Codelist\"]\n",
    "    try:\n",
    "        df = pd.read_csv(\"reference/components.csv\")\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "    except:\n",
    "        raise\n",
    "    # add measures and attributes\n",
    "    data = {\n",
    "        \"Label\":[],\n",
    "        \"Description\":[],\n",
    "        \"Component Type\":[],\n",
    "        \"Codelist\":[]\n",
    "    }\n",
    "    for measure in details[\"attributes to add\"][\"Measure Type\"].keys():\n",
    "        data[\"Label\"].append(measure)\n",
    "        data[\"Description\"].append(\"\")\n",
    "        data[\"Component Type\"].append(\"Measure\")\n",
    "        data[\"Codelist\"].append(\"\")\n",
    "    attributes_to_add = [x for x in details[\"attributes to add\"].keys() if x != \"Measure Type\"]\n",
    "    attributes_to_add = attributes_to_add + details[\"existing attributes\"]\n",
    "    for attribute in attributes_to_add:\n",
    "        data[\"Label\"].append(attribute)\n",
    "        data[\"Description\"].append(\"\")\n",
    "        data[\"Component Type\"].append(\"Attribute\")\n",
    "        data[\"Codelist\"].append(\"\")\n",
    "    for code_list_url in code_list_urls_from_dataset:\n",
    "        # Get the codelist id\n",
    "        code_list_id = \"cmd \" + code_list_url.split(\"/\")[-4]\n",
    "        # Where non standard handling is required, call it then go to next code list\n",
    "        if code_list_id in NON_STANDARD.keys():\n",
    "            continue\n",
    "        data[\"Label\"].append(code_list_id.replace(\"-\", \" \"))\n",
    "        data[\"Description\"].append(\"\")\n",
    "        data[\"Component Type\"].append(\"Dimension\")\n",
    "        data[\"Codelist\"].append(\"http://gss-data.org.uk/def/concept-scheme/\"+code_list_id)\n",
    "    df = pd.concat([df, pd.DataFrame().from_dict(data)])\n",
    "    df = df.fillna(\"\")\n",
    "    df = df.drop_duplicates()\n",
    "    df.to_csv(\"reference/components.csv\", index=False)\n",
    "def populate_columns_csv_from_list_of_code_list_urls(code_list_urls_from_dataset, details):\n",
    "    columns=[\"title\", \"name\", \"component_attachment\", \"property_template\", \"value_template\",\n",
    "                                   \"datatype\", \"value_transformation\", \"regex\", \"range\"]\n",
    "    try:\n",
    "        df = pd.read_csv(\"reference/columns.csv\")\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "    except:\n",
    "        raise\n",
    "    # Start with Value and Measure Type column as default (have to have a value definition)\n",
    "    data = {\n",
    "        \"title\":[\"Value\", \"Measure Type\"],\n",
    "        \"name\":[\"value\", \"measure_type\"],\n",
    "        \"component_attachment\":[\"qb:dimension\", \"qb:attribute\"],\n",
    "        \"property_template\":[\"http://purl.org/linked-data/cube#measureType\", \"\"],\n",
    "        \"value_template\":[\"http://gss-data.org.uk/def/measure/{measure_type}\", \"http://gss-data.org.uk/def/measure/{measure_type}\"],\n",
    "        \"datatype\":[\"number\", \"string\"],\n",
    "        \"value_transformation\":[\"\", \"\"],\n",
    "        \"regex\":[\"\", \"\"],\n",
    "        \"range\":[\"\", \"\"]\n",
    "    }\n",
    "    # First, add the measures (so anything from details that goes into the \"Measure Type\" column)\n",
    "    # and any attributes identified by our cmd-info.json\n",
    "    attributes_to_write = []\n",
    "    for mtype_or_attribute, instructions in details[\"attributes to add\"].items():\n",
    "        if mtype_or_attribute == \"Measure Type\":\n",
    "            for measure_type in instructions.keys():\n",
    "                data[\"title\"].append(\"{}\".format(measure_type))\n",
    "                data[\"name\"].append(\"{}\".format(measure_type.lower().replace(\"-\", \"-\")))\n",
    "                data[\"component_attachment\"].append(\"qb:measure\")\n",
    "                data[\"property_template\"].append(\"\")\n",
    "                data[\"value_template\"].append(\"\")\n",
    "                data[\"datatype\"].append(\"string\")\n",
    "                data[\"value_transformation\"].append(\"\")\n",
    "                data[\"regex\"].append(\"\")\n",
    "                data[\"range\"].append(\"\")\n",
    "        else:\n",
    "            attributes_to_write.append(mtype_or_attribute)\n",
    "    attributes_to_write = attributes_to_write + details[\"existing attributes\"]\n",
    "    for attribute in attributes_to_write:\n",
    "        data[\"title\"].append(\"{}\".format(attribute))\n",
    "        data[\"name\"].append(\"{}\".format(attribute.lower().replace(\"-\", \"-\")))\n",
    "        data[\"component_attachment\"].append(\"qb:attribute\")\n",
    "        prop = \"http://gss-data.org.uk/def/attribute/{}\".format(attribute.replace(\" \", \"-\").lower())\n",
    "        data[\"property_template\"].append(prop)\n",
    "        data[\"value_template\"].append(prop + \"/{\" + attribute.lower().replace(\" \", \"_\") + \"}\")\n",
    "        data[\"datatype\"].append(\"string\")\n",
    "        data[\"value_transformation\"].append(\"\")\n",
    "        data[\"regex\"].append(\"\")\n",
    "        data[\"range\"].append(\"\")           \n",
    "    # Then add the dimensions using the codelist urls\n",
    "    for code_list_url in code_list_urls_from_dataset:\n",
    "        # Get the codelist id\n",
    "        code_list_id = \"cmd-\" + code_list_url.split(\"/\")[-4]\n",
    "        # Where non standard handling is required, call it then go to next code list\n",
    "        if code_list_id in NON_STANDARD.keys():\n",
    "            data = NON_STANDARD[code_list_id][\"write_column\"](data)\n",
    "        else:\n",
    "            data[\"title\"].append(code_list_id.replace(\"-\", \" \"))\n",
    "            data[\"name\"].append(code_list_id.replace(\"-\", \"_\"))\n",
    "            data[\"component_attachment\"].append(\"qb:dimension\")\n",
    "            data[\"property_template\"].append(\"http://gss-data.org.uk/def/dimension/\"+code_list_id)\n",
    "            data[\"value_template\"].append(\"http://gss-data.org.uk/def/concept/\"+code_list_id+\"/{\"+code_list_id.replace(\"-\", \"_\")+\"}\")\n",
    "            data[\"datatype\"].append(\"string\")\n",
    "            data[\"value_transformation\"].append(\"slugize\")\n",
    "            data[\"regex\"].append(\"\")\n",
    "            data[\"range\"].append(\"\")\n",
    "    df = pd.concat([df, pd.DataFrame().from_dict(data)])\n",
    "    df = df.fillna(\"\")\n",
    "    df = df.drop_duplicates()\n",
    "    df.to_csv(\"reference/columns.csv\", index=False)\n",
    "def codelists_metadata_from_list_of_code_lists(code_list_urls_from_dataset):\n",
    "    tables = []\n",
    "    for code_list_url in code_list_urls_from_dataset:\n",
    "        # Get the codelist id\n",
    "        code_list_id = \"cmd \" + code_list_url.split(\"/\")[-4]\n",
    "        # Where non standard handling is required, call it then go to next code list\n",
    "        if code_list_id in NON_STANDARD.keys():\n",
    "            continue\n",
    "        table = {\n",
    "            \"url\": \"codelists/{}.csv\".format(code_list_id.lower()),\n",
    "            \"tableSchema\": \"https://gss-cogs.github.io/ref_common/codelist-schema.json\",\n",
    "            \"rdfs:label\": code_list_id.replace(\"-\", \" \").lower()\n",
    "        }\n",
    "        tables.append(table)\n",
    "    metadata_dict = {\n",
    "      \"@context\": [\"http://www.w3.org/ns/csvw\", {\"@language\": \"en\"}],\n",
    "      \"tables\": tables\n",
    "    }\n",
    "    with open(\"reference/codelists-metadata.json\" , \"w\") as f:\n",
    "        json.dump(metadata_dict, f)\n",
    "        \n",
    "def generate_reference_data():\n",
    "    with open(\"data.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        for dataset_id, details in data.items():\n",
    "            url = [dataset_id]\n",
    "            # Populate /reference/codelists\n",
    "            code_list_urls_from_dataset = get_list_of_code_list_url_for_list_of_datasets(url)\n",
    "            populate_codelist_reference_csvs_from_codelist_urls(code_list_urls_from_dataset)\n",
    "            # Populuate ../reference/columns.csv\n",
    "            populate_columns_csv_from_list_of_code_list_urls(code_list_urls_from_dataset, details)\n",
    "            # Populate ../reference/components.csv\n",
    "            components_csv_from_list_of_code_list_urls(code_list_urls_from_dataset, details)\n",
    "            # Populate ../reference/codelists-metadata.json\n",
    "            codelists_metadata_from_list_of_code_lists(code_list_urls_from_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
